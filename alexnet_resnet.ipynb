{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from structures import LateralInhibition, LIBlock\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "TRAIN_NORMALIZE = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.33)),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN.tolist(), std=IMAGENET_STD.tolist()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "TEST_NORMALIZE = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN.tolist(), std=IMAGENET_STD.tolist()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def deprocess(img):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(mean=[0, 0, 0], std=(1.0 / IMAGENET_STD).tolist()),\n",
    "            transforms.Normalize(mean=(-IMAGENET_MEAN).tolist(), std=[1, 1, 1]),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    )\n",
    "    return transform(img)\n",
    "\n",
    "\n",
    "def load_datas(batch_size=128, root=\"\"):\n",
    "    train_dataset = ImageFolder(root=f\"{root}imagenet-mini/train\", transform=TRAIN_NORMALIZE)\n",
    "    test_dataset = ImageFolder(root=f\"{root}imagenet-mini/val\", transform=TEST_NORMALIZE)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_datas()\n",
    "TRAIN_SIZE, TEST_SIZE = len(train_loader.dataset), len(test_loader.dataset)\n",
    "\n",
    "print(f\"train dataset: {TRAIN_SIZE}, test_dataset: {TEST_SIZE}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, num_epochs=90, batch_accumulation=2, eval_freq=5, comment=\"\", verbose=0\n",
    "):\n",
    "    writer = SummaryWriter(comment=comment)\n",
    "\n",
    "\n",
    "    # Setup training\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    # loss and accuracy records\n",
    "    train_loss_record = []\n",
    "    train_accuracy_record = []\n",
    "    test_loss_record = []\n",
    "    test_accuracy_record = []\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, correct = 0, 0\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            pred = output.argmax(dim=1)\n",
    "\n",
    "            # compute batch accuracy\n",
    "            correct += torch.sum(labels == pred).sum().item()\n",
    "\n",
    "            # compute the loss and accumulate it\n",
    "            loss = criterion(output, labels) / batch_accumulation\n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "\n",
    "            if (batch_idx + 1) % batch_accumulation:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # decrease learning rate\n",
    "        # scheduler.step()\n",
    "\n",
    "        total_loss /= TRAIN_SIZE\n",
    "        accuracy = correct / TRAIN_SIZE\n",
    "\n",
    "        writer.add_scalar(\"Train/loss\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Train/accuracy\", accuracy, epoch)\n",
    "\n",
    "        train_loss_record.append(total_loss.item())\n",
    "        train_accuracy_record.append(accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"[{epoch + 1:2d}/{num_epochs}] loss_train: {total_loss:.2E} accuracy_train: {accuracy:.2%}\"\n",
    "            )\n",
    "\n",
    "        if (epoch + 1) % eval_freq:\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_loss, correct = 0, 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "                pred = output.argmax(dim=1)\n",
    "\n",
    "                correct += torch.sum(labels == pred).sum().item()\n",
    "\n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss\n",
    "\n",
    "            test_loss /= TEST_SIZE\n",
    "            accuracy = correct / TEST_SIZE\n",
    "\n",
    "            writer.add_scalar(\"Test/loss\", test_loss, epoch)\n",
    "            writer.add_scalar(\"Test/accuracy\", accuracy, epoch)\n",
    "\n",
    "            test_loss_record.append(test_loss.item())\n",
    "            test_accuracy_record.append(accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"loss_test: {total_loss:.2E} accuracy_test: {accuracy:.2%}\")\n",
    "\n",
    "    # saving logs and model\n",
    "    log_path = \"logs/\"\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    # find last model run id\n",
    "    max_run_id = 0\n",
    "    for path in glob.glob(os.path.join(log_path, model_name + \"_[0-9]*\")):\n",
    "        file_name = os.path.basename(path)\n",
    "        ext = file_name.split(\"_\")[-1]\n",
    "        if (\n",
    "            model_name == \"_\".join(file_name.split(\"_\")[:-1])\n",
    "            and ext.isdigit()\n",
    "            and int(ext) > max_run_id\n",
    "        ):\n",
    "            max_run_id = int(ext)\n",
    "\n",
    "    file_name = model_name + f\"_{max_run_id+1}\"\n",
    "    save_dir = os.path.join(log_path, file_name)\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "    log = {\n",
    "        \"train_loss\": train_loss_record,\n",
    "        \"train_accuracy\": train_accuracy_record,\n",
    "        \"test_loss\": test_loss_record,\n",
    "        \"test_accuracy\": test_accuracy_record,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(save_dir, \"log.pkl\"), \"wb\") as f:\n",
    "        pk.dump(log, f)\n",
    "\n",
    "    torch.save(model, os.path.join(save_dir, \"model.pth\"))\n",
    "\n",
    "    print(f\"Model saved in: {save_dir}\")\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model = model.eval()\n",
    "    correct = 0\n",
    "    for _, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        pred = torch.argmax(model(images), dim=1)\n",
    "        correct += torch.sum(labels == pred).sum().item()\n",
    "\n",
    "    print(f\"accuracy: {correct / len(data_loader.dataset):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights_heatmap(model):\n",
    "    assert hasattr(model, \"log\")\n",
    "\n",
    "    weights = [t.flatten().detach().cpu() for t in model.log[\"W\"]]\n",
    "\n",
    "    w_min = torch.cat(weights).min()\n",
    "    w_max = torch.cat(weights).max()\n",
    "\n",
    "    bins = np.linspace(w_min, w_max, 20)\n",
    "    counts = np.zeros((len(weights), len(bins) - 1))\n",
    "\n",
    "    for i, W in enumerate(weights):\n",
    "        for j in range(len(bins) - 1):\n",
    "            counts[i][j] = ((W >= bins[j]) & (W < bins[j + 1])).sum().item()\n",
    "\n",
    "    counts /= counts.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    labels = [r\"$LI_{}$\".format(i + 1) for i in range(counts.shape[0])]\n",
    "    xticks = [f\"{bins[i] + bins[i+1] / 2:.2f}\" for i in range(bins.size - 1)]\n",
    "\n",
    "    ax.imshow(counts, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "    ax.set_xticks(np.arange(counts.shape[1]), xticks, rotation=45)\n",
    "    ax.set_yticks(np.arange(counts.shape[0]), labels)\n",
    "\n",
    "    plt.title(\"LI-layers weights heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_log(model_path, key=\"accuracy\"):\n",
    "    with open(f\"{model_path}/log.pkl\", \"rb\") as f:\n",
    "        log = pk.load(f)\n",
    "\n",
    "    model_name = model_path.split(\"/\")[1].split(\"_\")[0]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax[0].plot(log[f\"train_{key}\"], label=f\"{model_name}\")\n",
    "    ax[0].set_xlabel(\"epoch\")\n",
    "    ax[0].set_ylabel(key)\n",
    "    ax[0].set_title(\"fTrain {key}\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(log[f\"test_{key}\"], label=f\"{model_name}\")\n",
    "    ax[1].set_xlabel(\"epoch\")\n",
    "    ax[1].set_ylabel(key)\n",
    "    ax[1].set_title(f\"Test {key}\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_datas(batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(weights=None).to(device)\n",
    "train_model(alexnet, 90, 2, 5, f\"_AlexNet\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"logs/AlexNet_1\"\n",
    "\n",
    "model = torch.load(f\"{model_path}/model.pth\")\n",
    "evaluate(model, test_loader)\n",
    "plot_log(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet+LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetLI(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super(AlexNetLI, self).__init__()\n",
    "\n",
    "        alexnet = models.alexnet(weights=weights)\n",
    "\n",
    "        self.log = {\"W\": [], \"m\": [], \"v\": [], \"b\": []}\n",
    "\n",
    "        # Rebuild alexnet features, by adding a LI layer after each convolutions'\n",
    "        # activation function\n",
    "        features = list(alexnet.features.children())\n",
    "        new_features = []\n",
    "\n",
    "        for i, l in enumerate(features):\n",
    "            new_features.append(l)\n",
    "            if isinstance(l, nn.ReLU):\n",
    "                li = LateralInhibition(features[i - 1].out_channels, weights=li_weights)\n",
    "                new_features.append(li)\n",
    "                self.log[\"W\"].append(li.weights)\n",
    "                self.log[\"m\"].append(li.m)\n",
    "                self.log[\"v\"].append(li.v)\n",
    "                self.log[\"b\"].append(li.b)\n",
    "\n",
    "        self.features = nn.Sequential(*new_features)\n",
    "\n",
    "        # Copy all the non-convolutional parts of AlexNet\n",
    "        self.avg_pool = alexnet.avgpool\n",
    "        self.classifier = alexnet.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnetLI = AlexNetLI(weights=None).to(device)\n",
    "train_model(alexnetLI, 90, 2, 5, f\"_AlexNet+LI\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"logs/AlexNetLI_1\"\n",
    "\n",
    "model = torch.load(f\"{model_path}/model.pth\")\n",
    "evaluate(model, test_loader)\n",
    "plot_log(model_path)\n",
    "plot_weights_heatmap(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet+BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetBatchNorm(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super(AlexNetBatchNorm, self).__init__()\n",
    "\n",
    "        alexnet = models.alexnet(weights=weights)\n",
    "\n",
    "        # Rebuild alexnet features, by adding a BatchNorm layer after each convolutions'\n",
    "        # activation function\n",
    "        features = list(alexnet.features.children())\n",
    "        new_features = []\n",
    "\n",
    "        for i, l in enumerate(features):\n",
    "            new_features.append(l)\n",
    "            if isinstance(l, nn.ReLU):\n",
    "                new_features.append(nn.BatchNorm2d(features[i-1].out_channels))\n",
    "\n",
    "        self.features = nn.Sequential(*new_features)\n",
    "\n",
    "        # Copy all the non-convolutional parts of AlexNet\n",
    "        self.avg_pool = alexnet.avgpool\n",
    "        self.classifier = alexnet.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    alexnetBN = AlexNetBatchNorm().to(device)\n",
    "    train_model(alexnetBN, comment=\"_AlexNet+BatchNorm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet+GroupNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetGroupNorm(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super(AlexNetGroupNorm, self).__init__()\n",
    "\n",
    "        alexnet = models.alexnet(weights=weights)\n",
    "\n",
    "        # Rebuild alexnet features, by adding a LayerNorm layer after each convolutions'\n",
    "        # activation function\n",
    "        features = list(alexnet.features.children())\n",
    "        new_features = []\n",
    "        \n",
    "        for i, l in enumerate(features):\n",
    "            new_features.append(l)\n",
    "            if isinstance(l, nn.ReLU):\n",
    "                new_features.append(nn.GroupNorm(1, features[i-1].out_channels))\n",
    "\n",
    "        self.features = nn.Sequential(*new_features)\n",
    "\n",
    "        # Copy all the non-convolutional parts of AlexNet\n",
    "        self.avg_pool = alexnet.avgpool\n",
    "        self.classifier = alexnet.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    alexnetGN = AlexNetGroupNorm().to(device)\n",
    "    train_model(alexnetGN, comment=\"_AlexNet+GroupNorm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_datas(batch_size=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    resnet18 = models.resnet18(weights=None).to(device)\n",
    "    train_model(resnet18, num_epochs=100, comment=\"_ResNet18\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet+LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLI(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super(ResNetLI, self).__init__() \n",
    "        \n",
    "        resnet = models.resnet18(weights=weights)\n",
    "\n",
    "        self.log = {\"W\": [], \"m\": [], \"v\": [], \"b\": []}\n",
    "        \n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.li1 = LateralInhibition(self.conv1.out_channels)\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = self.convert_layer_blocks(resnet.layer1)\n",
    "        self.layer2 = self.convert_layer_blocks(resnet.layer2)\n",
    "        self.layer3 = self.convert_layer_blocks(resnet.layer3)\n",
    "        self.layer4 = self.convert_layer_blocks(resnet.layer4)\n",
    "        \n",
    "        # Copy all the non-convolutional parts of ResNet\n",
    "        self.avgpool = resnet.avgpool\n",
    "        self.fc = resnet.fc\n",
    "\n",
    "        # Add the \"plain\" li params to the log\n",
    "        self.log[\"W\"].append(self.li1.weights)\n",
    "        self.log[\"m\"].append(self.li1.m)\n",
    "        self.log[\"v\"].append(self.li1.v)\n",
    "        self.log[\"b\"].append(self.li1.b)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.li1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def convert_layer_blocks(self, layer: nn.Sequential):\n",
    "        new_layer = []\n",
    "\n",
    "        for l in layer:\n",
    "            if isinstance(l, BasicBlock):\n",
    "                liblock = LIBlock(l)\n",
    "                new_layer.append(liblock)\n",
    "                \n",
    "                self.log[\"W\"].append(liblock.li.weights)\n",
    "                self.log[\"m\"].append(liblock.li.m)\n",
    "                self.log[\"v\"].append(liblock.li.v)\n",
    "                self.log[\"b\"].append(liblock.li.b)\n",
    "            else:\n",
    "                new_layer.append(l)\n",
    "\n",
    "        return nn.Sequential(*new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    resnetLI = ResNetLI().to(device)\n",
    "    train_model(resnetLI, num_epochs=100, comment=\"_ResNet18+BatchNorm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetLI = ResNetLI().to(device)\n",
    "train_model(resnetLI, num_epochs=1, comment=\"_ResNet18+BatchNorm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = enumerate(train_loader)\n",
    "idx, (image, label) = next(batch)\n",
    "\n",
    "image, label = image.to(device), label.to(device)\n",
    "\n",
    "LI = LateralInhibition().cuda()\n",
    "output = LI(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 13\n",
    "img = deprocess(image[idx])\n",
    "display(img)\n",
    "\n",
    "li_img = deprocess(output[idx])\n",
    "display(li_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a14f325d447890c1aa81d5004c3a59981b75ede9581a60409be6700f02a9947e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

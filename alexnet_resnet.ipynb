{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from structures import LateralInhibition, LIBlock\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 34745, test_dataset: 3923\n"
     ]
    }
   ],
   "source": [
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "TRAIN_NORMALIZE = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN.tolist(), std=IMAGENET_STD.tolist()),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.33)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "TEST_NORMALIZE = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN.tolist(), std=IMAGENET_STD.tolist()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def deprocess(img):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(mean=[0, 0, 0], std=(1.0 / IMAGENET_STD).tolist()),\n",
    "            transforms.Normalize(mean=(-IMAGENET_MEAN).tolist(), std=[1, 1, 1]),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    )\n",
    "    return transform(img)\n",
    "\n",
    "\n",
    "def load_datas(batch_size=128):\n",
    "    train_dataset = ImageFolder(root=\"imagenet-mini/train\", transform=TRAIN_NORMALIZE)\n",
    "    test_dataset = ImageFolder(root=\"imagenet-mini/val\", transform=TEST_NORMALIZE)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_datas()\n",
    "TRAIN_SIZE, TEST_SIZE = len(train_loader.dataset), len(test_loader.dataset)\n",
    "\n",
    "print(f\"train dataset: {TRAIN_SIZE}, test_dataset: {TEST_SIZE}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, max_epochs=10, batch_accumulation=2, eval_freq=2, comment=\"\", verbose=True):\n",
    "    writer = SummaryWriter(comment=comment)\n",
    "\n",
    "    # Create log dir\n",
    "    log_path = \"logs/\"\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    max_run_id = 0\n",
    "    for path in glob.glob(os.path.join(log_path, model_name + \"_[0-9]*\")):\n",
    "        file_name = os.path.basename(path)\n",
    "        ext = file_name.split(\"_\")[-1]\n",
    "        if (\n",
    "            model_name == \"_\".join(file_name.split(\"_\")[:-1])\n",
    "            and ext.isdigit()\n",
    "            and int(ext) > max_run_id\n",
    "        ):\n",
    "            max_run_id = int(ext)\n",
    "\n",
    "    file_name = model_name + f\"_{max_run_id+1}\"\n",
    "    save_dir = os.path.join(log_path, file_name)\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "    train_loss_record = []\n",
    "    train_accuracy_record = []\n",
    "    test_loss_record = []\n",
    "    test_accuracy_record = []\n",
    "\n",
    "    # Setup training\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(max_epochs):\n",
    "        total_loss, correct = 0, 0\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            pred = output.argmax(dim=1)\n",
    "\n",
    "            loss = criterion(output, labels) / batch_accumulation\n",
    "            total_loss += loss\n",
    "\n",
    "            correct += torch.sum(labels == pred).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (batch_idx + 1) % batch_accumulation:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss /= TRAIN_SIZE\n",
    "        accuracy = correct / TRAIN_SIZE\n",
    "\n",
    "        writer.add_scalar(\"Train/loss\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Train/accuracy\", accuracy, epoch)\n",
    "\n",
    "        train_loss_record.append(total_loss.item())\n",
    "        train_accuracy_record.append(accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{epoch + 1:2d}/{max_epochs}] loss_train: {total_loss:.2E} accuracy_train: {accuracy:.2%}\")\n",
    "\n",
    "        if not epoch % eval_freq:\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_loss, correct = 0, 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "                pred = output.argmax(dim=1)\n",
    "\n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss\n",
    "\n",
    "                correct += torch.sum(labels == pred).sum().item()\n",
    "\n",
    "            test_loss /= TEST_SIZE\n",
    "            accuracy = correct / TEST_SIZE\n",
    "\n",
    "            writer.add_scalar(\"Test/loss\", test_loss, epoch)\n",
    "            writer.add_scalar(\"Test/accuracy\", accuracy, epoch)\n",
    "\n",
    "            test_loss_record.append(test_loss.item())\n",
    "            test_accuracy_record.append(accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"loss_test: {total_loss:.2E} accuracy_test: {accuracy:.2%}\")\n",
    "\n",
    "        if verbose and hasattr(model, \"log\"):\n",
    "            W = torch.concatenate([t.flatten() for t in model.log[\"W\"]])\n",
    "            m = torch.tensor([t.item() for t in model.log[\"m\"]])\n",
    "            v = torch.tensor([t.item() for t in model.log[\"v\"]])\n",
    "            b = torch.tensor([t.item() for t in model.log[\"b\"]])\n",
    "\n",
    "            print(\"LI-layers params (avg, min, max):\")\n",
    "            print(f\"* W: ({W.mean():.2f}, {W.min():.2f}, {W.max():.2f})\")\n",
    "            print(f\"* m: ({m.mean():.2f}, {m.min():.2f}, {b.max():.2f})\")\n",
    "            print(f\"* v: ({v.mean():.2f}, {v.min():.2f}, {v.max():.2f})\")\n",
    "            print(f\"* b: ({b.mean():.2f}, {b.min():.2f}, {b.max():.2f})\")\n",
    "\n",
    "    # saving logs\n",
    "    log = {\n",
    "        \"train_loss\": train_loss_record,\n",
    "        \"train_accuracy\": train_accuracy_record,\n",
    "        \"test_loss\": test_loss_record,\n",
    "        \"test_accuracy\": test_accuracy_record,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(save_dir, \"log.pkl\"), \"wb\") as f:\n",
    "        pk.dump(log, f)\n",
    "\n",
    "    torch.save(model, os.path.join(save_dir, \"model.pth\"))\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, mode=\"train\"):\n",
    "    correct = 0\n",
    "    for _, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        pred = torch.argmax(model(images), dim=1)\n",
    "        correct += torch.sum(labels == pred).sum().item()\n",
    "\n",
    "    print(f\"{mode} accuracy: {correct / len(data_loader.dataset):.2%}\")\n",
    "\n",
    "\n",
    "def plot_weights_heatmap(model):\n",
    "    assert hasattr(model, \"log\")\n",
    "\n",
    "    weights = [t.flatten().detach().cpu() for t in alexnetLI.log[\"W\"]]\n",
    "\n",
    "    w_min = torch.concatenate(weights).min()\n",
    "    w_max = torch.concatenate(weights).max()\n",
    "\n",
    "    bins = np.linspace(w_min, w_max, 20)\n",
    "    counts = np.zeros((len(weights), len(bins) - 1))\n",
    "\n",
    "    # Compter les valeurs dans chaque plage pour chaque tensor\n",
    "    for i, W in enumerate(weights):\n",
    "        for j in range(len(bins) - 1):\n",
    "            counts[i][j] = ((W >= bins[j]) & (W < bins[j + 1])).sum().item()\n",
    "\n",
    "    counts /= counts.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    labels = [r\"$LI_{}$\".format(i + 1) for i in range(counts.shape[0])]\n",
    "    xticks = [f\"{bins[i] + bins[i+1] / 2:.2f}\" for i in range(bins.size - 1)]\n",
    "\n",
    "    ax.imshow(counts, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "    ax.set_xticks(np.arange(counts.shape[1]), xticks, rotation=45)\n",
    "    ax.set_yticks(np.arange(counts.shape[0]), labels)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # colors = [\"Reds\", \"Blues\", \"Greens\", \"Oranges\", \"Purples\"]\n",
    "\n",
    "    # fig, axes = plt.subplots(5, 1, figsize=(8,2), sharex=True)\n",
    "\n",
    "    # for i, ax in enumerate(axes):\n",
    "    #     ax.imshow(counts[i].reshape(1, -1), cmap=colors[i], vmin=w_min, vmax=w_max)\n",
    "    #     ax.set_ylabel(r\"$LI_{}$\".format(i+1))\n",
    "    #     ax.set_yticks([])\n",
    "    #     ax.set_aspect('equal')\n",
    "\n",
    "    # xticks = [f\"{bins[i] + bins[i+1] / 2:.2f}\" for i in range(bins.size - 1)]\n",
    "    # ax.set_xticks(np.arange(counts.shape[1]), xticks, rotation=45)\n",
    "\n",
    "    # fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_datas(batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = models.alexnet(weights=\"DEFAULT\").to(device)\n",
    "alexnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 53.05%\n"
     ]
    }
   ],
   "source": [
    "evaluate(alexnet, train_loader, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 52.23%\n"
     ]
    }
   ],
   "source": [
    "evaluate(alexnet, test_loader, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] loss_train: 1.15E-02 accuracy_train: 37.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] loss_train: 1.01E-02 accuracy_train: 42.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 1.01E-02 accuracy_test: 37.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:31<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/10] loss_train: 9.50E-03 accuracy_train: 45.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/10] loss_train: 8.76E-03 accuracy_train: 49.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 8.76E-03 accuracy_test: 34.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/10] loss_train: 8.18E-03 accuracy_train: 51.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/10] loss_train: 7.78E-03 accuracy_train: 53.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 7.78E-03 accuracy_test: 33.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/10] loss_train: 7.37E-03 accuracy_train: 55.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/10] loss_train: 7.14E-03 accuracy_train: 57.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 7.14E-03 accuracy_test: 32.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:33<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/10] loss_train: 6.68E-03 accuracy_train: 59.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:32<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] loss_train: 6.57E-03 accuracy_train: 60.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 6.57E-03 accuracy_test: 31.68%\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.alexnet(weights=\"DEFAULT\").to(device)\n",
    "train_model(alexnet, 10, 2, 2, f\"ALEXNET\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet+LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexnetLI(nn.Module):\n",
    "    def __init__(self, weights=\"DEFAULT\", li_weights=\"zeros\", freeze=False):\n",
    "        super(AlexnetLI, self).__init__()\n",
    "\n",
    "        alexnet = models.alexnet(weights=weights)\n",
    "\n",
    "        if freeze:\n",
    "            for param in alexnet.parameters():\n",
    "                param.require_grad = False\n",
    "\n",
    "        self.log = {\"W\": [], \"m\": [], \"v\": [], \"b\": []}\n",
    "\n",
    "        # Rebuild alexnet features, by adding a LI layer after each convolutions'\n",
    "        # activation function\n",
    "        features = list(alexnet.features.children())\n",
    "        new_features = []\n",
    "\n",
    "        for i, l in enumerate(features):\n",
    "            new_features.append(l)\n",
    "            if isinstance(l, nn.ReLU):\n",
    "                li = LateralInhibition(features[i - 1].out_channels, weights=li_weights)\n",
    "                new_features.append(li)\n",
    "                self.log[\"W\"].append(li.weights)\n",
    "                self.log[\"m\"].append(li.m)\n",
    "                self.log[\"v\"].append(li.v)\n",
    "                self.log[\"b\"].append(li.b)\n",
    "\n",
    "        self.features = nn.Sequential(*new_features)\n",
    "\n",
    "        # Copy all the non-convolutional parts of AlexNet\n",
    "        self.avg_pool = alexnet.avgpool\n",
    "        self.classifier = alexnet.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:45<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] loss_train: 1.13E-02 accuracy_train: 37.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:44<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] loss_train: 1.01E-02 accuracy_train: 43.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 1.01E-02 accuracy_test: 37.04%\n",
      "LI-layers params (avg, min, max):\n",
      "* W: (0.00, -0.02, 0.13)\n",
      "* m: (-0.08, -0.17, -0.05)\n",
      "* v: (0.95, 0.74, 1.09)\n",
      "* b: (-0.09, -0.17, -0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:44<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/10] loss_train: 9.24E-03 accuracy_train: 46.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:44<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/10] loss_train: 8.54E-03 accuracy_train: 50.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 8.54E-03 accuracy_test: 34.41%\n",
      "LI-layers params (avg, min, max):\n",
      "* W: (0.00, -0.02, 0.18)\n",
      "* m: (-0.12, -0.23, -0.09)\n",
      "* v: (0.96, 0.63, 1.17)\n",
      "* b: (-0.14, -0.23, -0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:45<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/10] loss_train: 8.06E-03 accuracy_train: 52.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:45<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/10] loss_train: 7.55E-03 accuracy_train: 55.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 7.55E-03 accuracy_test: 33.55%\n",
      "LI-layers params (avg, min, max):\n",
      "* W: (0.00, -0.03, 0.22)\n",
      "* m: (-0.14, -0.29, -0.13)\n",
      "* v: (0.99, 0.58, 1.26)\n",
      "* b: (-0.17, -0.28, -0.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:44<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/10] loss_train: 7.12E-03 accuracy_train: 57.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:44<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/10] loss_train: 6.76E-03 accuracy_train: 59.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 6.76E-03 accuracy_test: 32.27%\n",
      "LI-layers params (avg, min, max):\n",
      "* W: (0.00, -0.04, 0.24)\n",
      "* m: (-0.16, -0.34, -0.12)\n",
      "* v: (0.99, 0.55, 1.29)\n",
      "* b: (-0.18, -0.32, -0.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:44<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/10] loss_train: 6.43E-03 accuracy_train: 61.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:45<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] loss_train: 6.10E-03 accuracy_train: 62.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 6.10E-03 accuracy_test: 32.07%\n",
      "LI-layers params (avg, min, max):\n",
      "* W: (0.00, -0.05, 0.26)\n",
      "* m: (-0.18, -0.36, -0.15)\n",
      "* v: (0.99, 0.56, 1.32)\n",
      "* b: (-0.21, -0.34, -0.15)\n"
     ]
    }
   ],
   "source": [
    "alexnetLI = AlexnetLI().to(device) \n",
    "train_model(alexnetLI, 10, 2, 2, f\"ALEXNET_LI 256 log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torch.load(\"logs/AlexnetLI_3/model.pth\")\n",
    "plot_weights_heatmap(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet+BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexnetBatchNorm(nn.Module):\n",
    "    def __init__(self, weights=\"DEFAULT\"):\n",
    "        super(AlexnetBatchNorm, self).__init__()\n",
    "\n",
    "        alexnet = models.alexnet(weights=weights)\n",
    "\n",
    "        # Rebuild alexnet features, by adding a BatchNorm layer after each convolutions'\n",
    "        # activation function\n",
    "        features = list(alexnet.features.children())\n",
    "        new_features = []\n",
    "\n",
    "        for i, l in enumerate(features):\n",
    "            new_features.append(l)\n",
    "            if isinstance(l, nn.ReLU):\n",
    "                new_features.append(nn.BatchNorm2d(features[i-1].out_channels))\n",
    "\n",
    "        self.features = nn.Sequential(*new_features)\n",
    "\n",
    "        # Copy all the non-convolutional parts of AlexNet\n",
    "        self.avg_pool = alexnet.avgpool\n",
    "        self.classifier = alexnet.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:39<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] loss_train: 1.28E-02 accuracy_train: 32.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:36<00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] loss_train: 1.03E-02 accuracy_train: 42.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 1.03E-02 accuracy_test: 35.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:37<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/10] loss_train: 9.16E-03 accuracy_train: 47.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:34<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/10] loss_train: 8.37E-03 accuracy_train: 51.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 8.37E-03 accuracy_test: 34.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:35<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/10] loss_train: 7.65E-03 accuracy_train: 54.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:34<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/10] loss_train: 7.15E-03 accuracy_train: 57.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 7.15E-03 accuracy_test: 34.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:35<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/10] loss_train: 6.74E-03 accuracy_train: 59.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:34<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/10] loss_train: 6.39E-03 accuracy_train: 61.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 6.39E-03 accuracy_test: 33.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:35<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/10] loss_train: 5.97E-03 accuracy_train: 64.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:35<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] loss_train: 5.77E-03 accuracy_train: 65.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 5.77E-03 accuracy_test: 32.09%\n"
     ]
    }
   ],
   "source": [
    "alexnetBN = AlexnetBatchNorm().to(device)\n",
    "train_model(alexnetBN, 10, 2, 2, \"ALEXNET_BatchNorm 256\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet+GroupNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexnetGroupNorm(nn.Module):\n",
    "    def __init__(self, weights=\"DEFAULT\"):\n",
    "        super(AlexnetGroupNorm, self).__init__()\n",
    "\n",
    "        alexnet = models.alexnet(weights=weights)\n",
    "\n",
    "        # Rebuild alexnet features, by adding a LayerNorm layer after each convolutions'\n",
    "        # activation function\n",
    "        features = list(alexnet.features.children())\n",
    "        new_features = []\n",
    "        \n",
    "        for i, l in enumerate(features):\n",
    "            new_features.append(l)\n",
    "            if isinstance(l, nn.ReLU):\n",
    "                new_features.append(nn.GroupNorm(1, features[i-1].out_channels))\n",
    "\n",
    "        self.features = nn.Sequential(*new_features)\n",
    "\n",
    "        # Copy all the non-convolutional parts of AlexNet\n",
    "        self.avg_pool = alexnet.avgpool\n",
    "        self.classifier = alexnet.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] loss_train: 1.29E-02 accuracy_train: 32.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] loss_train: 1.04E-02 accuracy_train: 41.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 1.04E-02 accuracy_test: 37.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:41<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/10] loss_train: 9.26E-03 accuracy_train: 46.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:43<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/10] loss_train: 8.60E-03 accuracy_train: 50.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 8.60E-03 accuracy_test: 35.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/10] loss_train: 7.95E-03 accuracy_train: 53.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/10] loss_train: 7.30E-03 accuracy_train: 56.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 7.30E-03 accuracy_test: 35.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/10] loss_train: 6.90E-03 accuracy_train: 58.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:39<00:00,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/10] loss_train: 6.42E-03 accuracy_train: 61.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 6.42E-03 accuracy_test: 34.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/10] loss_train: 6.17E-03 accuracy_train: 62.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:40<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] loss_train: 5.73E-03 accuracy_train: 65.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_test: 5.73E-03 accuracy_test: 32.04%\n"
     ]
    }
   ],
   "source": [
    "alexnetGN = AlexnetGroupNorm().to(device)\n",
    "train_model(alexnetGN, 10, 2, 2, \"ALEXNET_GroupNorm 256\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_datas(batch_size=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(weights=\"DEFAULT\").to(device)\n",
    "resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 65.26%\n"
     ]
    }
   ],
   "source": [
    "evaluate(resnet18, train_loader, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 66.51%\n"
     ]
    }
   ],
   "source": [
    "evaluate(resnet18, test_loader, mode=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet+LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLI(nn.Module):\n",
    "    def __init__(self, weights=\"DEFAULT\", freeze=False):\n",
    "        super(ResnetLI, self).__init__() \n",
    "        \n",
    "        resnet = models.resnet18(weights=weights)\n",
    "\n",
    "        if freeze:\n",
    "            for param in resnet.parameters():\n",
    "                param.require_grad = False\n",
    "\n",
    "        self.log = {\"W\": [], \"m\": [], \"v\": [], \"b\": []}\n",
    "        \n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.li1 = LateralInhibition(self.conv1.out_channels)\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = self.convert_layer_blocks(resnet.layer1)\n",
    "        self.layer2 = self.convert_layer_blocks(resnet.layer2)\n",
    "        self.layer3 = self.convert_layer_blocks(resnet.layer3)\n",
    "        self.layer4 = self.convert_layer_blocks(resnet.layer4)\n",
    "        \n",
    "        # Copy all the non-convolutional parts of ResNet\n",
    "        self.avgpool = resnet.avgpool\n",
    "        self.fc = resnet.fc\n",
    "\n",
    "        # Add the \"plain\" li params to the log\n",
    "        self.log[\"W\"].append(self.li1.weights)\n",
    "        self.log[\"m\"].append(self.li1.m)\n",
    "        self.log[\"v\"].append(self.li1.v)\n",
    "        self.log[\"b\"].append(self.li1.b)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.li1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def convert_layer_blocks(self, layer: nn.Sequential):\n",
    "        new_layer = []\n",
    "\n",
    "        for l in layer:\n",
    "            if isinstance(l, BasicBlock):\n",
    "                liblock = LIBlock(l)\n",
    "                new_layer.append(liblock)\n",
    "                \n",
    "                self.log[\"W\"].append(self.liblock.li.weights)\n",
    "                self.log[\"m\"].append(self.liblock.li.m)\n",
    "                self.log[\"v\"].append(self.liblock.li.v)\n",
    "                self.log[\"b\"].append(self.liblock.li.b)\n",
    "            else:\n",
    "                new_layer.append(l)\n",
    "\n",
    "        return nn.Sequential(*new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetLI = ResnetLI().to(device)\n",
    "train_model(resnetLI, 10, 2, 2, \"RESNET_LI\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = enumerate(train_loader)\n",
    "idx, (image, label) = next(batch)\n",
    "\n",
    "image, label = image.to(device), label.to(device)\n",
    "\n",
    "LI = LateralInhibition().cuda()\n",
    "output = LI(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 13\n",
    "img = deprocess(image[idx])\n",
    "display(img)\n",
    "\n",
    "li_img = deprocess(output[idx])\n",
    "display(li_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da2e2b763ce854165d4087dd5d7e36e1631e69a252c45c2f7bdfd54f03b8f37b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
